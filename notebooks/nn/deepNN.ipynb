{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DNN-Hyssop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Justin Tan\n",
    "\n",
    "Date: Mar. 17 2017\n",
    "\n",
    "A simple deep neural network for binary classification (signal and $K^* \\gamma$ background) on Belle II MC data for $B \\rightarrow \\rho^0 \\gamma$. Separation of $K^* \\gamma$ from signal is especially challenging because of the kinematic similarity and identical topology of both decay modes. \n",
    "\n",
    "Update 20/03: Added batch normalization, TensorBoard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('learning_rate', 1e-5,\n",
    "                           \"\"\"Beta for Adam optimizer.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 128,\n",
    "                            \"\"\"Number of training samples subject to SGD per iteration.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('n_epochs', 20,\n",
    "                            \"\"\"Number of epochs to train over.\"\"\")\n",
    "tf.app.flags.DEFINE_string('summaries_dir', '/home/ubuntu/radiative/graphs/tensorboard',\n",
    "                             \"\"\"Directory to hold tf summary data.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('n_threads', 4,\n",
    "                            \"\"\"Number of threads that the queue runner runs in parallel during enqueue op.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_weights(shape):\n",
    "    # Return weight tensor of given shape using Xavier initialization\n",
    "    W = tf.get_variable(\"weights\", shape = shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_biases(shape):\n",
    "    # Return bias tensor of given shape with small initialized constant value\n",
    "    b = tf.get_variable(\"biases\", shape = shape, initializer = tf.constant_initializer(0.01))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout_op(layer, keep_prob):\n",
    "    # Neurons in given layer have retention probability keep_prob to combat overfitting\n",
    "    fc_drop = tf.nn.dropout(layer, keep_prob)\n",
    "    return fc_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer_ops(x, shape, name, keep_prob, activation=tf.nn.relu):\n",
    "    # Add operations to graph to construct hidden layers\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # scope.reuse_variables() # otherwise tf.get_variable() checks that already existing vars are not shared by accident\n",
    "        weights = layer_weights(shape = shape)\n",
    "        biases = layer_biases(shape = [shape[1]])\n",
    "        \n",
    "        # Apply non-linearity. Default is ReLU\n",
    "        actv = activation(tf.matmul(x, weights) + biases)\n",
    "        layer_output = dropout_op(actv, keep_prob)\n",
    "        \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readout_ops(x, shape, name, keep_prob, activation=tf.nn.relu):\n",
    "    # Don't apply non-linearity, dropout on output layer\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        weights = layer_weights(shape = shape)\n",
    "        biases = layer_biases(shape = [shape[1]])\n",
    "        layer_output = tf.matmul(x, weights) + biases\n",
    "        \n",
    "        tf.summary.histogram('readout', layer_output)\n",
    "\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch normalization normalizes each scalar feature $x^k$ in each training mini-batch. The normalized output is linearly scaled so that the set of possible transformations contains the identity:\n",
    "$$ \\hat{x}^{(k)} = \\frac{x^{(k)} - E[x^{(k)}]}{\\sqrt{\\mathrm{Var}[x^{(k)}] + \\epsilon}}, \\quad \\quad \\theta^k = \\gamma^{(k)} \\hat{x}^{(k)} + \\beta^{(k)} $$\n",
    "Given a mini-batch $\\mathcal{B} = \\{x_{1...m}\\}$, this is a transformation $\\mathrm{BN}(\\gamma,\\beta) : x_{1,...,m} \\rightarrow \\theta_{1,...,m}$. The $\\gamma, \\beta$ tensors become learnable parameters for each layer. When batch-normalizing a network, any layer than previously received $x$ as the input now receives $\\mathrm{BN}(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BN_layer_ops(x, shape, name, keep_prob, phase, activation=tf.nn.relu):\n",
    "    # High-level implementation of BN\n",
    "    with tf.variable_scope(name) as scope:\n",
    "         # scope.reuse_variables() # otherwise tf.get_variable() checks that already existing vars are not shared by accident\n",
    "        weights = layer_weights(shape = shape)\n",
    "        biases = layer_biases(shape = [shape[1]])\n",
    "        z_BN = tf.matmul(x, weights) + biases\n",
    "        \n",
    "        # Place BN transform before or after non-linearity?\n",
    "        theta_BN = tf.contrib.layers.batch_norm(z_BN, center=True, scale=True, is_training=phase, scope='bn') #, fused = True)\n",
    "        BN_actv = activation(theta_BN)\n",
    "        BN_layer_output = dropout_op(BN_actv, keep_prob)\n",
    "\n",
    "    return BN_layer_output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BN_layer_ops_manual(x, shape, name, keep_prob, activation=tf.nn.relu):\n",
    "    # Low level implementation of BN\n",
    "    # Apply batch normalization - normalizes a tensor by mean, variance, takes the linear transform of the normalized activation\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # scope.reuse_variables() # otherwise tf.get_variable() checks that already existing vars are not shared by accident\n",
    "        weights = layer_weights(shape = shape)\n",
    "        biases = layer_biases(shape = [shape[1]])\n",
    "        z_BN = tf.matmul(x, weights) + biases\n",
    "        batch_mean, batch_var = tf.nn.moments(z_BN, [0])\n",
    "        \n",
    "        gamma = tf.get_variable(name = 'gamma', shape=[shape[1]], initializer=tf.ones_initializer())\n",
    "        beta = tf.get_variable(name = 'beta', shape = [shape[1]], initializer = tf.constant_initializer(0.01))\n",
    "        \n",
    "        theta_BN = tf.nn.batch_normalization(z_BN, mean = batch_mean, variance = batch_variance, \n",
    "                                       offset = beta, scale = gamma, variance_epsilon = 1e-3)\n",
    "        \n",
    "        # Apply non-linearity. Default is ReLU\n",
    "        BN_layer_output = activation(theta_BN)\n",
    "        \n",
    "        if name != 'readout': # Don't apply dropout on output layer\n",
    "            BN_layer_output = dropout_op(layer_output, keep_prob)\n",
    "            \n",
    "    return BN_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_variables(scope_name):\n",
    "    # Fetch variables within variable scope_name\n",
    "    with tf.variable_scope(scope_name, reuse=True):\n",
    "        W = tf.get_variable(\"weights\")\n",
    "        b = tf.get_variable(\"biases\")\n",
    "        return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def onehot(y):\n",
    "    # Convert labels to one-hot encoding\n",
    "    onehots = np.zeros((y.shape[0],2))\n",
    "    for i in range(onehots.shape[0]):\n",
    "        onehots[i][int(y[i])] = 1\n",
    "    return onehots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_onehots(labels, depth=2):\n",
    "    # Converts signal/background labels to one-hot encoding\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
    "    return onehot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y_true, y_pred):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true, logits = y_pred))\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_operation(loss_op, learning_rate = 1e-4):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss_op, name = 'train_op')\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_operation(y_true, y_pred):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_true,1), tf.argmax(y_pred,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_feed_iterator(features, labels, batch_size=128):\n",
    "    # Takes raw data as numpy arrays and feeds into computation graph\n",
    "    # Input data has shape [batch_size, n_features]\n",
    "    while True:\n",
    "        # Shuffle labels and features: shuf_features = features[idxs], shuf_labels = labels[idxs]\n",
    "        idxs = np.arange(0, features.shape[0]); np.random.shuffle(idxs)\n",
    "        random_batch_idx = np.random.choice(idxs, size=batch_size, replace = False)\n",
    "        \n",
    "        x_batch = features[random_batch_idx] #.astype('float32')\n",
    "        labels_batch = labels[random_batch_idx]\n",
    "        #onehot_labels_batch = tf.one_hot(indices=tf.cast(labels_batch, tf.int32), depth=2)\n",
    "                \n",
    "        return [x_batch, labels_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def epoch_shuffle(features, labels):\n",
    "    # Shuffles features, labels at end of epoch\n",
    "    rand_idx = np.random.permutation(features.shape[0])\n",
    "    features = features[rand_idx]\n",
    "    labels = labels[rand_idx]\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholder + Hyperparameter Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start building computation graph by creating nodes for efficient gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data as DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_hdf('/home/ubuntu/radiative/df/rho0/std_norm_sig_cus.h5', 'df')\n",
    "df_X_train, df_X_test, df_y_train, df_y_test = train_test_split(df[df.columns[:-1]], df['labels'], test_size = 0.075, random_state=432)\n",
    "X_train = df_X_train.values\n",
    "X_test = df_X_test.values\n",
    "y_train = onehot(df_y_train.values)\n",
    "y_test = onehot(df_y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1] # Number of feature columns in dataset\n",
    "hidden_layer_nodes = [1024, 512, 1024, 512, 512] # Number of neurons in hidden layers\n",
    "summaries_dir_custom = '/home/ubuntu/radiative/graphs/tensorboard/rho0/cus'\n",
    "summaries_dir_cont = '/home/ubuntu/radiative/graphs/tensorboard/rho0/cont'\n",
    "checkpoints_dir = '/home/ubuntu/radiative/checkpoints/rho0'\n",
    "n_threads = 4 # number of threads for multi-threaded input queue system\n",
    "learning_rate = 1e-4\n",
    "training_steps = 40000\n",
    "batch_size = 256; dropout_prob = 0.75\n",
    "v_acc_best = 0; position = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Declare placeholder tensors\n",
    "x = tf.placeholder(tf.float32, shape = [None, n_features]) # Input features, 58 features per data point\n",
    "y_true = tf.placeholder(tf.float32, shape = [None, 2]) # Target output classes\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "training_phase = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Strictly initialization of weights, biases - this should be run only once\n",
    "def build_layers(x, hidden_layer_nodes, keep_prob):\n",
    "    hidden_1 = add_layer_ops(x, shape = [n_features, hidden_layer_nodes[0]], name = 'hidden1', keep_prob = keep_prob)\n",
    "    hidden_2 = add_layer_ops(hidden_1, shape = [hidden_layer_nodes[0], hidden_layer_nodes[1]], name = 'hidden2', keep_prob = keep_prob)\n",
    "    hidden_3 = add_layer_ops(hidden_2, shape = [hidden_layer_nodes[1], hidden_layer_nodes[2]], name = 'hidden3', keep_prob = keep_prob)\n",
    "    readout = add_layer_ops(hidden_3, shape = [hidden_layer_nodes[2], 2], name = 'readout', keep_prob = 1.0)\n",
    "    \n",
    "    return readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_ops(y, y_pred):\n",
    "    train_step_size = 1e-5 # experiment with this\n",
    "\n",
    "    # Average cross-entropy over the batch dimension as the total loss\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = y_pred))\n",
    "    train_step = tf.train.AdamOptimizer(train_step_size).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    config = tf.ConfigProto(device_count={\"CPU\": 4}, inter_op_parallelism_threads=4, intra_op_parallelism_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With batch normalization! Run below cell to compare perfomance\n",
    "hidden_1 = BN_layer_ops(x, shape = [n_features, hidden_layer_nodes[0]], name = 'BNhidden1', keep_prob = keep_prob, phase = training_phase)\n",
    "hidden_2 = BN_layer_ops(hidden_1, shape = [hidden_layer_nodes[0], hidden_layer_nodes[1]], name = 'BNhidden2', keep_prob = keep_prob, phase = training_phase)\n",
    "hidden_3 = BN_layer_ops(hidden_2, shape = [hidden_layer_nodes[1], hidden_layer_nodes[2]], name = 'BNhidden3', keep_prob = keep_prob, phase = training_phase)\n",
    "hidden_4 = BN_layer_ops(hidden_3, shape = [hidden_layer_nodes[2], hidden_layer_nodes[3]], name = 'BNhidden4', keep_prob = keep_prob, phase = training_phase)\n",
    "hidden_5 = BN_layer_ops(hidden_4, shape = [hidden_layer_nodes[3], hidden_layer_nodes[4]], name = 'BNhidden5', keep_prob = keep_prob, phase = training_phase)\n",
    "\n",
    "# Readout layer is the model's unnormalized prediction \n",
    "readout = readout_ops(hidden_5, shape = [hidden_layer_nodes[4], 2], name = 'readout', keep_prob = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_1 = hidden_layer_ops(x, shape = [n_features, hidden_layer_nodes[0]], name = 'hidden1', keep_prob = keep_prob)\n",
    "hidden_2 = hidden_layer_ops(hidden_1, shape = [hidden_layer_nodes[0], hidden_layer_nodes[1]], name = 'hidden2', keep_prob = keep_prob)\n",
    "hidden_3 = hidden_layer_ops(hidden_2, shape = [hidden_layer_nodes[1], hidden_layer_nodes[2]], name = 'hidden3', keep_prob = keep_prob)\n",
    "hidden_4 = hidden_layer_ops(hidden_3, shape = [hidden_layer_nodes[2], hidden_layer_nodes[3]], name = 'hidden4', keep_prob = keep_prob)\n",
    "hidden_5 = hidden_layer_ops(hidden_4, shape = [hidden_layer_nodes[3], hidden_layer_nodes[4]], name = 'hidden5', keep_prob = keep_prob)\n",
    "\n",
    "# Readout layer is the model's unnormalized prediction \n",
    "readout = readout_ops(hidden_5, shape = [hidden_layer_nodes[4], 2], name = 'readout', keep_prob = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run these operations only during inference\n",
    "prediction_op = tf.nn.softmax(readout)\n",
    "classification_op = tf.argmax(prediction_op, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorShape([Dimension(1024), Dimension(512)]), TensorShape([Dimension(512)])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can retrieve initalized network parameters as (weights, biases)\n",
    "params4 = fetch_variables('BNhidden4')\n",
    "[param.get_shape() for param in params4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last output layer can be interpreted as the class scores.\n",
    "\n",
    "Define the cross-entropy loss function: with network output $\\hat{y} = g(\\mathbf{w} \\cdot \\mathbf{x} + \\mathbf{b})$ the observed (true) probabilities are given as $ p \\in \\{y, 1-y\\}$, and the predicted probability is $q \\in \\{\\hat{y}, 1- \\hat{y} \\}$; cross-entropy is a measure of the similarity between $p$ and $q$:\n",
    "\n",
    "$$ H(p,q) = - \\sum_i p_i \\log(q_i) $$\n",
    "\n",
    "The typical loss function is given by the average over all cross-entropies in the sample:\n",
    "\n",
    "$$ L(\\mathbf{w}) = \\frac{1}{N}\\sum_i H_i(p,q) $$\n",
    "\n",
    "Reduce overfitting by applying dropout on each layer. Units and their connections are automatically dropped from the network during training to aid generalization during test time. The full unthinned network is used to evaluate the test data. For input units the optimal probability of retention is 1, for hidden layers we need to experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add operations for loss minimization\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "cross_entropy_op = cross_entropy(y_true = y_true, y_pred = readout)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    # Ensures that we execute the update_ops before performing the train_step\n",
    "    train_op = training_operation(cross_entropy_op, learning_rate = learning_rate)\n",
    "    \n",
    "accuracy = prediction_operation(y_true = y_true, y_pred = readout)\n",
    "# Save checkpoints\n",
    "saver = tf.train.Saver()\n",
    "# Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "merge_op = tf.summary.merge_all()\n",
    "# Write summary data to disk for TensorBoard visualization\n",
    "train_writer = tf.summary.FileWriter(summaries_dir_custom + '/train', graph = tf.get_default_graph())\n",
    "test_writer = tf.summary.FileWriter(summaries_dir_custom + '/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part adds the training operations to the graph needed to minimize the loss via some form of stochastic gradient descent. Training proceeds over N iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\t|\tTraining accuracy: 0.546875\t|\tValidation Accuracy: 0.476562 (0.607 s) *\n",
      "Step: 200\t|\tTraining accuracy: 0.722656\t|\tValidation Accuracy: 0.722656 (14.585 s) *\n",
      "Step: 400\t|\tTraining accuracy: 0.796875\t|\tValidation Accuracy: 0.824219 (28.359 s) *\n",
      "Step: 600\t|\tTraining accuracy: 0.785156\t|\tValidation Accuracy: 0.816406 (42.131 s) \n",
      "Step: 800\t|\tTraining accuracy: 0.757812\t|\tValidation Accuracy: 0.8125 (56.322 s) \n",
      "Step: 1000\t|\tTraining accuracy: 0.753906\t|\tValidation Accuracy: 0.789062 (70.366 s) \n",
      "Step: 1200\t|\tTraining accuracy: 0.734375\t|\tValidation Accuracy: 0.828125 (84.371 s) *\n",
      "Step: 1400\t|\tTraining accuracy: 0.785156\t|\tValidation Accuracy: 0.785156 (98.263 s) \n",
      "End of epoch.\n",
      "Step: 1600\t|\tTraining accuracy: 0.757812\t|\tValidation Accuracy: 0.761719 (112.259 s) \n",
      "Step: 1800\t|\tTraining accuracy: 0.800781\t|\tValidation Accuracy: 0.800781 (126.237 s) \n",
      "Step: 2000\t|\tTraining accuracy: 0.789062\t|\tValidation Accuracy: 0.8125 (140.340 s) \n",
      "Step: 2200\t|\tTraining accuracy: 0.785156\t|\tValidation Accuracy: 0.808594 (154.219 s) \n",
      "Step: 2400\t|\tTraining accuracy: 0.828125\t|\tValidation Accuracy: 0.835938 (168.160 s) *\n",
      "Step: 2600\t|\tTraining accuracy: 0.808594\t|\tValidation Accuracy: 0.777344 (181.869 s) \n",
      "Step: 2800\t|\tTraining accuracy: 0.789062\t|\tValidation Accuracy: 0.804688 (195.688 s) \n",
      "End of epoch.\n",
      "Step: 3000\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.796875 (209.888 s) \n",
      "Step: 3200\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.804688 (223.723 s) \n",
      "Step: 3400\t|\tTraining accuracy: 0.773438\t|\tValidation Accuracy: 0.820312 (237.379 s) \n",
      "Step: 3600\t|\tTraining accuracy: 0.792969\t|\tValidation Accuracy: 0.851562 (251.143 s) *\n",
      "Step: 3800\t|\tTraining accuracy: 0.773438\t|\tValidation Accuracy: 0.832031 (264.966 s) \n",
      "Step: 4000\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.820312 (278.863 s) \n",
      "Step: 4200\t|\tTraining accuracy: 0.800781\t|\tValidation Accuracy: 0.855469 (292.864 s) *\n",
      "Step: 4400\t|\tTraining accuracy: 0.824219\t|\tValidation Accuracy: 0.804688 (306.680 s) \n",
      "End of epoch.\n",
      "Step: 4600\t|\tTraining accuracy: 0.8125\t|\tValidation Accuracy: 0.824219 (320.932 s) \n",
      "Step: 4800\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.800781 (334.865 s) \n",
      "Step: 5000\t|\tTraining accuracy: 0.820312\t|\tValidation Accuracy: 0.8125 (348.651 s) \n",
      "Step: 5200\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.808594 (362.382 s) \n",
      "Step: 5400\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.828125 (376.253 s) \n",
      "Step: 5600\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.816406 (389.943 s) \n",
      "Step: 5800\t|\tTraining accuracy: 0.804688\t|\tValidation Accuracy: 0.832031 (403.797 s) \n",
      "End of epoch.\n",
      "Step: 6000\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.859375 (417.568 s) *\n",
      "Step: 6200\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.863281 (431.308 s) *\n",
      "Step: 6400\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.824219 (445.218 s) \n",
      "Step: 6600\t|\tTraining accuracy: 0.816406\t|\tValidation Accuracy: 0.851562 (459.225 s) \n",
      "Step: 6800\t|\tTraining accuracy: 0.808594\t|\tValidation Accuracy: 0.800781 (472.878 s) \n",
      "Step: 7000\t|\tTraining accuracy: 0.804688\t|\tValidation Accuracy: 0.859375 (486.506 s) \n",
      "Step: 7200\t|\tTraining accuracy: 0.820312\t|\tValidation Accuracy: 0.851562 (500.548 s) \n",
      "Step: 7400\t|\tTraining accuracy: 0.8125\t|\tValidation Accuracy: 0.808594 (514.274 s) \n",
      "End of epoch.\n",
      "Step: 7600\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.824219 (528.240 s) \n",
      "Step: 7800\t|\tTraining accuracy: 0.824219\t|\tValidation Accuracy: 0.804688 (542.314 s) \n",
      "Step: 8000\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.84375 (556.251 s) \n",
      "Step: 8200\t|\tTraining accuracy: 0.878906\t|\tValidation Accuracy: 0.84375 (570.269 s) \n",
      "Step: 8400\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.839844 (584.030 s) \n",
      "Step: 8600\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.851562 (597.861 s) \n",
      "Step: 8800\t|\tTraining accuracy: 0.789062\t|\tValidation Accuracy: 0.855469 (611.666 s) \n",
      "End of epoch.\n",
      "Step: 9000\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.824219 (625.752 s) \n",
      "Step: 9200\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.886719 (639.389 s) *\n",
      "Step: 9400\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.847656 (653.166 s) \n",
      "Step: 9600\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.902344 (666.946 s) *\n",
      "Step: 9800\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.851562 (680.620 s) \n",
      "Step: 10000\t|\tTraining accuracy: 0.8125\t|\tValidation Accuracy: 0.84375 (694.191 s) \n",
      "Step: 10200\t|\tTraining accuracy: 0.820312\t|\tValidation Accuracy: 0.832031 (707.978 s) \n",
      "Step: 10400\t|\tTraining accuracy: 0.828125\t|\tValidation Accuracy: 0.851562 (721.541 s) \n",
      "End of epoch.\n",
      "Step: 10600\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.863281 (735.254 s) \n",
      "Step: 10800\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.828125 (749.043 s) \n",
      "Step: 11000\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.78125 (762.665 s) \n",
      "Step: 11200\t|\tTraining accuracy: 0.882812\t|\tValidation Accuracy: 0.847656 (776.039 s) \n",
      "Step: 11400\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.847656 (789.605 s) \n",
      "Step: 11600\t|\tTraining accuracy: 0.878906\t|\tValidation Accuracy: 0.847656 (803.082 s) \n",
      "Step: 11800\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.882812 (816.676 s) \n",
      "End of epoch.\n",
      "Step: 12000\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.792969 (830.537 s) \n",
      "Step: 12200\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.828125 (843.978 s) \n",
      "Step: 12400\t|\tTraining accuracy: 0.828125\t|\tValidation Accuracy: 0.769531 (857.611 s) \n",
      "Step: 12600\t|\tTraining accuracy: 0.886719\t|\tValidation Accuracy: 0.808594 (871.252 s) \n",
      "Step: 12800\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.859375 (884.713 s) \n",
      "Step: 13000\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.828125 (898.327 s) \n",
      "Step: 13200\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.898438 (912.135 s) \n",
      "Step: 13400\t|\tTraining accuracy: 0.898438\t|\tValidation Accuracy: 0.878906 (925.704 s) \n",
      "End of epoch.\n",
      "Step: 13600\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.839844 (939.571 s) \n",
      "Step: 13800\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.882812 (952.832 s) \n",
      "Step: 14000\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.835938 (966.277 s) \n",
      "Step: 14200\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.828125 (980.095 s) \n",
      "Step: 14400\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.839844 (993.882 s) \n",
      "Step: 14600\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.824219 (1007.556 s) \n",
      "Step: 14800\t|\tTraining accuracy: 0.878906\t|\tValidation Accuracy: 0.839844 (1021.317 s) \n",
      "End of epoch.\n",
      "Step: 15000\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.847656 (1035.100 s) \n",
      "Step: 15200\t|\tTraining accuracy: 0.828125\t|\tValidation Accuracy: 0.878906 (1049.040 s) \n",
      "Step: 15400\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.847656 (1062.760 s) \n",
      "Step: 15600\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.851562 (1076.310 s) \n",
      "Step: 15800\t|\tTraining accuracy: 0.816406\t|\tValidation Accuracy: 0.851562 (1090.070 s) \n",
      "Step: 16000\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.851562 (1103.611 s) \n",
      "Step: 16200\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.863281 (1117.226 s) \n",
      "Step: 16400\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.855469 (1131.051 s) \n",
      "End of epoch.\n",
      "Step: 16600\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.894531 (1144.829 s) \n",
      "Step: 16800\t|\tTraining accuracy: 0.796875\t|\tValidation Accuracy: 0.871094 (1158.721 s) \n",
      "Step: 17000\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.832031 (1172.527 s) \n",
      "Step: 17200\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.820312 (1186.085 s) \n",
      "Step: 17400\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.84375 (1199.646 s) \n",
      "Step: 17600\t|\tTraining accuracy: 0.800781\t|\tValidation Accuracy: 0.871094 (1213.283 s) \n",
      "Step: 17800\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.863281 (1227.030 s) \n",
      "End of epoch.\n",
      "Step: 18000\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.828125 (1240.668 s) \n",
      "Step: 18200\t|\tTraining accuracy: 0.804688\t|\tValidation Accuracy: 0.832031 (1254.249 s) \n",
      "Step: 18400\t|\tTraining accuracy: 0.800781\t|\tValidation Accuracy: 0.835938 (1267.982 s) \n",
      "Step: 18600\t|\tTraining accuracy: 0.824219\t|\tValidation Accuracy: 0.875 (1281.539 s) \n",
      "Step: 18800\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.804688 (1294.998 s) \n",
      "Step: 19000\t|\tTraining accuracy: 0.800781\t|\tValidation Accuracy: 0.851562 (1308.562 s) \n",
      "Step: 19200\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.847656 (1322.137 s) \n",
      "Step: 19400\t|\tTraining accuracy: 0.886719\t|\tValidation Accuracy: 0.820312 (1335.653 s) \n",
      "End of epoch.\n",
      "Step: 19600\t|\tTraining accuracy: 0.816406\t|\tValidation Accuracy: 0.828125 (1349.777 s) \n",
      "Step: 19800\t|\tTraining accuracy: 0.804688\t|\tValidation Accuracy: 0.8125 (1363.609 s) \n",
      "Step: 20000\t|\tTraining accuracy: 0.828125\t|\tValidation Accuracy: 0.839844 (1377.268 s) \n",
      "Step: 20200\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.839844 (1390.907 s) \n",
      "Step: 20400\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.804688 (1404.693 s) \n",
      "Step: 20600\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.867188 (1418.336 s) \n",
      "Step: 20800\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.882812 (1432.052 s) \n",
      "End of epoch.\n",
      "Step: 21000\t|\tTraining accuracy: 0.820312\t|\tValidation Accuracy: 0.847656 (1446.307 s) \n",
      "Step: 21200\t|\tTraining accuracy: 0.894531\t|\tValidation Accuracy: 0.820312 (1460.052 s) \n",
      "Step: 21400\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.824219 (1473.749 s) \n",
      "Step: 21600\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.828125 (1487.670 s) \n",
      "Step: 21800\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.867188 (1501.650 s) \n",
      "Step: 22000\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.8125 (1515.321 s) \n",
      "Step: 22200\t|\tTraining accuracy: 0.882812\t|\tValidation Accuracy: 0.867188 (1528.984 s) \n",
      "Step: 22400\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.867188 (1542.736 s) \n",
      "End of epoch.\n",
      "Step: 22600\t|\tTraining accuracy: 0.882812\t|\tValidation Accuracy: 0.832031 (1556.392 s) \n",
      "Step: 22800\t|\tTraining accuracy: 0.804688\t|\tValidation Accuracy: 0.796875 (1569.962 s) \n",
      "Step: 23000\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.847656 (1583.388 s) \n",
      "Step: 23200\t|\tTraining accuracy: 0.882812\t|\tValidation Accuracy: 0.886719 (1597.232 s) \n",
      "Step: 23400\t|\tTraining accuracy: 0.886719\t|\tValidation Accuracy: 0.851562 (1610.667 s) \n",
      "Step: 23600\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.785156 (1624.446 s) \n",
      "Step: 23800\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.800781 (1638.289 s) \n",
      "End of epoch.\n",
      "Step: 24000\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.882812 (1652.325 s) \n",
      "Step: 24200\t|\tTraining accuracy: 0.882812\t|\tValidation Accuracy: 0.835938 (1665.938 s) \n",
      "Step: 24400\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.859375 (1679.834 s) \n",
      "Step: 24600\t|\tTraining accuracy: 0.902344\t|\tValidation Accuracy: 0.832031 (1693.532 s) \n",
      "Step: 24800\t|\tTraining accuracy: 0.804688\t|\tValidation Accuracy: 0.835938 (1707.381 s) \n",
      "Step: 25000\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.828125 (1721.436 s) \n",
      "Step: 25200\t|\tTraining accuracy: 0.820312\t|\tValidation Accuracy: 0.867188 (1735.036 s) \n",
      "Step: 25400\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.90625 (1748.843 s) *\n",
      "End of epoch.\n",
      "Step: 25600\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.875 (1762.736 s) \n",
      "Step: 25800\t|\tTraining accuracy: 0.820312\t|\tValidation Accuracy: 0.851562 (1776.542 s) \n",
      "Step: 26000\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.875 (1790.305 s) \n",
      "Step: 26200\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.855469 (1803.963 s) \n",
      "Step: 26400\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.835938 (1817.514 s) \n",
      "Step: 26600\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.839844 (1831.001 s) \n",
      "Step: 26800\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.835938 (1844.675 s) \n",
      "End of epoch.\n",
      "Step: 27000\t|\tTraining accuracy: 0.828125\t|\tValidation Accuracy: 0.867188 (1858.358 s) \n",
      "Step: 27200\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.898438 (1871.980 s) \n",
      "Step: 27400\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.828125 (1885.506 s) \n",
      "Step: 27600\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.832031 (1899.429 s) \n",
      "Step: 27800\t|\tTraining accuracy: 0.890625\t|\tValidation Accuracy: 0.875 (1913.071 s) \n",
      "Step: 28000\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.835938 (1926.495 s) \n",
      "Step: 28200\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.851562 (1940.224 s) \n",
      "Step: 28400\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.824219 (1954.089 s) \n",
      "End of epoch.\n",
      "Step: 28600\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.820312 (1967.956 s) \n",
      "Step: 28800\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.855469 (1981.576 s) \n",
      "Step: 29000\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.820312 (1995.145 s) \n",
      "Step: 29200\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.828125 (2009.004 s) \n",
      "Step: 29400\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.824219 (2022.763 s) \n",
      "Step: 29600\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.832031 (2036.261 s) \n",
      "Step: 29800\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.839844 (2049.714 s) \n",
      "End of epoch.\n",
      "Step: 30000\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.800781 (2063.639 s) \n",
      "Step: 30200\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.855469 (2077.501 s) \n",
      "Step: 30400\t|\tTraining accuracy: 0.785156\t|\tValidation Accuracy: 0.882812 (2091.284 s) \n",
      "Step: 30600\t|\tTraining accuracy: 0.894531\t|\tValidation Accuracy: 0.84375 (2105.026 s) \n",
      "Step: 30800\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.820312 (2118.694 s) \n",
      "Step: 31000\t|\tTraining accuracy: 0.878906\t|\tValidation Accuracy: 0.871094 (2132.444 s) \n",
      "Step: 31200\t|\tTraining accuracy: 0.816406\t|\tValidation Accuracy: 0.867188 (2145.970 s) \n",
      "Step: 31400\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.820312 (2159.390 s) \n",
      "End of epoch.\n",
      "Step: 31600\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.824219 (2173.062 s) \n",
      "Step: 31800\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.878906 (2186.765 s) \n",
      "Step: 32000\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.835938 (2200.669 s) \n",
      "Step: 32200\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.832031 (2214.828 s) \n",
      "Step: 32400\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.84375 (2228.454 s) \n",
      "Step: 32600\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.855469 (2242.182 s) \n",
      "Step: 32800\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.867188 (2256.189 s) \n",
      "End of epoch.\n",
      "Step: 33000\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.851562 (2270.118 s) \n",
      "Step: 33200\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.828125 (2283.681 s) \n",
      "Step: 33400\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.84375 (2297.146 s) \n",
      "Step: 33600\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.816406 (2310.852 s) \n",
      "Step: 33800\t|\tTraining accuracy: 0.828125\t|\tValidation Accuracy: 0.84375 (2324.549 s) \n",
      "Step: 34000\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.828125 (2338.057 s) \n",
      "Step: 34200\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.820312 (2351.543 s) \n",
      "Step: 34400\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.859375 (2365.078 s) \n",
      "End of epoch.\n",
      "Step: 34600\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.855469 (2378.729 s) \n",
      "Step: 34800\t|\tTraining accuracy: 0.894531\t|\tValidation Accuracy: 0.867188 (2392.280 s) \n",
      "Step: 35000\t|\tTraining accuracy: 0.886719\t|\tValidation Accuracy: 0.847656 (2405.679 s) \n",
      "Step: 35200\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.851562 (2419.309 s) \n",
      "Step: 35400\t|\tTraining accuracy: 0.835938\t|\tValidation Accuracy: 0.867188 (2433.084 s) \n",
      "Step: 35600\t|\tTraining accuracy: 0.859375\t|\tValidation Accuracy: 0.84375 (2446.778 s) \n",
      "Step: 35800\t|\tTraining accuracy: 0.824219\t|\tValidation Accuracy: 0.847656 (2460.420 s) \n",
      "End of epoch.\n",
      "Step: 36000\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.847656 (2474.407 s) \n",
      "Step: 36200\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.835938 (2487.870 s) \n",
      "Step: 36400\t|\tTraining accuracy: 0.863281\t|\tValidation Accuracy: 0.847656 (2501.326 s) \n",
      "Step: 36600\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.847656 (2515.119 s) \n",
      "Step: 36800\t|\tTraining accuracy: 0.871094\t|\tValidation Accuracy: 0.878906 (2529.245 s) \n",
      "Step: 37000\t|\tTraining accuracy: 0.808594\t|\tValidation Accuracy: 0.878906 (2542.917 s) \n",
      "Step: 37200\t|\tTraining accuracy: 0.832031\t|\tValidation Accuracy: 0.851562 (2556.908 s) \n",
      "End of epoch.\n",
      "Step: 37400\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.84375 (2571.059 s) \n",
      "Step: 37600\t|\tTraining accuracy: 0.84375\t|\tValidation Accuracy: 0.835938 (2584.738 s) \n",
      "Step: 37800\t|\tTraining accuracy: 0.808594\t|\tValidation Accuracy: 0.84375 (2598.452 s) \n",
      "Step: 38000\t|\tTraining accuracy: 0.824219\t|\tValidation Accuracy: 0.84375 (2612.058 s) \n",
      "Step: 38200\t|\tTraining accuracy: 0.847656\t|\tValidation Accuracy: 0.847656 (2625.615 s) \n",
      "Step: 38400\t|\tTraining accuracy: 0.851562\t|\tValidation Accuracy: 0.863281 (2639.347 s) \n",
      "Step: 38600\t|\tTraining accuracy: 0.855469\t|\tValidation Accuracy: 0.855469 (2653.105 s) \n",
      "Step: 38800\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.851562 (2666.915 s) \n",
      "End of epoch.\n",
      "Step: 39000\t|\tTraining accuracy: 0.816406\t|\tValidation Accuracy: 0.867188 (2680.691 s) \n",
      "Step: 39200\t|\tTraining accuracy: 0.875\t|\tValidation Accuracy: 0.839844 (2694.454 s) \n",
      "Step: 39400\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.871094 (2708.529 s) \n",
      "Step: 39600\t|\tTraining accuracy: 0.839844\t|\tValidation Accuracy: 0.839844 (2722.262 s) \n",
      "Step: 39800\t|\tTraining accuracy: 0.867188\t|\tValidation Accuracy: 0.871094 (2735.870 s) \n",
      "Model saved in file: /home/ubuntu/radiative/checkpoints/rho0/rho0_hyssop.ckpt-39999\n",
      "Training Complete. Epochs: 26\n",
      "\n",
      "Train accuracy: 0.853923\n",
      "Validation accuracy: 0.846555\n",
      "Duration: 2782.28 s\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # automatically closes upon exit\n",
    "    # Initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Launch the graph and train on randomly selected subset of training data\n",
    "    for step in range(training_steps):            \n",
    "        # Fetch input data from specified stream\n",
    "        if ((X_train.shape[0] - position) > batch_size):\n",
    "            batch_train = [X_train[position:position+batch_size], y_train[position:position+batch_size]]\n",
    "            position += batch_size\n",
    "        else:\n",
    "            # Epoch completed, reshuffle training data, labels\n",
    "            batch_train = [X_train[position:], y_train[position:]]\n",
    "            position = 0\n",
    "            X_train, y_train = epoch_shuffle(X_train, y_train)\n",
    "            print(\"End of epoch.\")\n",
    "            \n",
    "        # batch_test = data_feed_iterator(X_train.values[position:batch_size], y_train.values[position:batch_size], batch_size=batch_size)\n",
    "        feed_dict_train = {x: batch_train[0], y_true: batch_train[1], keep_prob: dropout_prob, training_phase: True}\n",
    "        \n",
    "        # Inject data into Tensors in computation graph - optimize this!\n",
    "        # train_op.run(feed_dict = feed_dict_train)\n",
    "        t_step, t_error = sess.run([train_op, cross_entropy_op], feed_dict = feed_dict_train)\n",
    "    \n",
    "        if step % 20 == 0:\n",
    "            # Record summaries\n",
    "            summary = sess.run(merge_op, feed_dict = feed_dict_train)\n",
    "            train_writer.add_summary(summary, step)\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            batch_val = data_feed_iterator(X_test, y_test, batch_size=batch_size)\n",
    "            improved = ''\n",
    "            # t_acc = accuracy.eval(feed_dict = {x: batch_test[0], y_true: batch_test[1], keep_prob = 1.0})\n",
    "            # v_acc = accuracy.eval(feed_dict = {x: batch_val[0], y_true: batch_val[1], keep_prob = 1.0})\n",
    "            t_acc = sess.run(accuracy, feed_dict = {x: batch_train[0], y_true: batch_train[1], keep_prob: 1.0, training_phase: False})\n",
    "            v_acc, v_summary = sess.run([accuracy, merge_op], feed_dict = {x: batch_val[0], y_true: batch_val[1], keep_prob: 1.0, training_phase: False})\n",
    "            test_writer.add_summary(v_summary, step)\n",
    "            \n",
    "            if v_acc > v_acc_best:\n",
    "                v_acc_best = v_acc\n",
    "                improved = '*'\n",
    "                \n",
    "            delta_t = time.time() - start_time\n",
    "            print(\"Step: %d\\t|\\tTraining accuracy: %g\\t|\\tValidation Accuracy: %g (%.3f s) %s\"\n",
    "                  %(step, t_acc, v_acc, delta_t, improved))\n",
    "\n",
    "    # Training complete\n",
    "    save_path = saver.save(sess, os.path.join(checkpoints_dir, 'rho0_hyssop.ckpt'), global_step = step)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "    final_train_accuracy = accuracy.eval(feed_dict = {x: X_train, y_true: y_train, keep_prob: 1.0, training_phase: False})\n",
    "    final_val_accuracy = accuracy.eval(feed_dict = {x: X_test, y_true: y_test, keep_prob: 1.0, training_phase: False})\n",
    "\n",
    "    delta_t = time.time() - start_time\n",
    "    NN_meta = \"Architecture: %s | Epochs: %d, Duration: %.2f s\" %(str(hidden_layer_nodes), training_steps*batch_size/(X_train.shape[0]), delta_t)    \n",
    "    \n",
    "    print(\"Training Complete. Epochs: %d\\n\" %(training_steps*batch_size/(X_train.shape[0])))\n",
    "    print(\"Train accuracy: %g\\nValidation accuracy: %g\" %(final_train_accuracy, final_val_accuracy))\n",
    "    print(\"Duration: %g s\" %(delta_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions\n",
    "Classification on a new instance is given by the softmax of the output of the final readout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load saved graph metadata in current default graph, restore in session\n",
    "saver = tf.train.import_meta_graph(os.path.join(checkpoints_dir, 'simple_model-39999.meta'))\n",
    "graph = tf.get_default_graph()\n",
    "checkpoint_to_restore = 'simple_model-39999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess: \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Restore the trained model\n",
    "    saver.restore(sess, os.path.join(checkpoints_dir, checkpoint_to_restore))\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "    feed_dict_train = {x: X_train, keep_prob: 1.0, training_phase: False}\n",
    "    feed_dict_test = {x: X_test, keep_prob: 1.0, training_phase: False}\n",
    "    \n",
    "    # Make predictions using the trained model\n",
    "    network_output_train, classifications_train = sess.run([prediction_op, classification_op], feed_dict = feed_dict_train)\n",
    "    network_output_test, classifications_test = sess.run([prediction_op, classification_op], feed_dict = feed_dict_test)\n",
    "    \n",
    "    delta_t = time.time() - start_time\n",
    "    print(\"Inference complete. Duration: %g s\" %(delta_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save neural network output to disk\n",
    "np.save('/home/ubuntu/radiative/df/rho0/arrays/n_train.npy', network_output_train)\n",
    "np.save('/home/ubuntu/radiative/df/rho0/arrays/y_train.npy', y_train)\n",
    "np.save('/home/ubuntu/radiative/df/rho0/arrays/n_test.npy', network_output_test)\n",
    "np.save('/home/ubuntu/radiative/df/rho0/arrays/y_test.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
